{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4836431cf1c4ca49685b64f67797356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32c2d40d8f994d3d99ed51cd05456692",
              "IPY_MODEL_a62df14790f14d4caa011b0adda07d96",
              "IPY_MODEL_48d5bcf62db740ada2b3541f715485b5"
            ],
            "layout": "IPY_MODEL_f68137df8dae40c098e82b291555c32e"
          }
        },
        "32c2d40d8f994d3d99ed51cd05456692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84af123733e74bff83a5bf66f0d4a84c",
            "placeholder": "​",
            "style": "IPY_MODEL_b9d39ba6cfd640ad8cd77554ff35e8fd",
            "value": "100%"
          }
        },
        "a62df14790f14d4caa011b0adda07d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbae073c244a4c0b999f6b80aa6c4c83",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22e7fb5d496348f1ac18d6238ecc63c3",
            "value": 3
          }
        },
        "48d5bcf62db740ada2b3541f715485b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d92339152f9a4e3d8618ecf25a7e2935",
            "placeholder": "​",
            "style": "IPY_MODEL_7fee22269bc248bf9672aecf975cffda",
            "value": " 3/3 [00:42&lt;00:00, 14.03s/it]"
          }
        },
        "f68137df8dae40c098e82b291555c32e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84af123733e74bff83a5bf66f0d4a84c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d39ba6cfd640ad8cd77554ff35e8fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbae073c244a4c0b999f6b80aa6c4c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e7fb5d496348f1ac18d6238ecc63c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d92339152f9a4e3d8618ecf25a7e2935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fee22269bc248bf9672aecf975cffda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Import the needed Libraries\n",
        "\n",
        "#### Documentation: https://pytorch.org/docs/stable/index.html\n",
        "#### Youtube Tutorial: https://www.learnpytorch.io/"
      ],
      "metadata": {
        "id": "ijakQ0TfEhqP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LReEUhW0EeZP"
      },
      "outputs": [],
      "source": [
        "# pytorch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# torchvision\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import datasets\n",
        "\n",
        "# torchtext\n",
        "import tochtext\n",
        "\n",
        "# torchaudio\n",
        "import torchaudio\n",
        "\n",
        "# standard data handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# machine learning\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# system\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "# timing and printing\n",
        "from tqdm.auto import tqdm\n",
        "from timeit import default_timer as timer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the available pytorch and Cuda (GPU) Version"
      ],
      "metadata": {
        "id": "3dBWIFpFFBHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pytroch and cuda version\n",
        "print(torch.__version__)\n",
        "\n",
        "# trochvision and cuda version\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "id": "05sFxzsbE64c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a8f472b-2e9f-4992-f519-d9a8e223d6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "0.15.2+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the available device\n",
        "\n",
        "1. CPU (Default)\n",
        "2. Cuda (GPU acceleration is accessible)"
      ],
      "metadata": {
        "id": "gFA1DwgMFSQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make device agnostic code (default is cpu)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Available device is: {device}\")"
      ],
      "metadata": {
        "id": "hxrucJHYFTgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de820ad8-1a02-434f-d9c4-45160e19c8d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available device is: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Helper files"
      ],
      "metadata": {
        "id": "PkhXIjCBsrrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filename\n",
        "filenames = [\"pytorch_helper_functions.py\"]\n",
        "\n",
        "for filename in filenames:\n",
        "  # download helper functions from repo\n",
        "  if Path(filename).is_file():\n",
        "    print(f\"{filename} already exists. Skipping download\")\n",
        "  else:\n",
        "    print(f\"Downlading {filename}.\")\n",
        "    request = requests.get(\"https://raw.githubusercontent.com/sl2000stat/PytorchIntroduction/master/pytorch_helper_functions.py\")\n",
        "    with open(filename, \"wb\") as f:\n",
        "      f.write(request.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fUTU8Jbsvrc",
        "outputId": "78f8e767-b5cc-4d14-9f8b-700513f2e7ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pytorch_helper_functions.py already exists. Skipping download\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### General Pytorch Workflow\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01_a_pytorch_workflow.png)\n",
        "\n",
        "1. **Getting data ready:** Data can be almost anything but to get started we're going to create a simple straight line\n",
        "2. **Building a model:**\tHere we'll create a model to learn patterns in the data, we'll also choose a loss function, optimizer and build a training loop.\n",
        "3. **Fitting the model to data (training):** We've got data and a model, now let's let the model (try to) find patterns in the (training) data.\n",
        "4. **Making predictions and evaluating a model (inference):**\tOur model's found patterns in the data, let's compare its findings to the actual (testing) data.\n",
        "5. **Tune the model:**\tFine tune the hyperparameter and select the optimal model.\n",
        "6. **Saving and loading a model:**\tYou may want to use your model elsewhere, or come back to it later, here we'll cover that.\n"
      ],
      "metadata": {
        "id": "Vv6MijmoFlZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Get the Data"
      ],
      "metadata": {
        "id": "ySooWdBJFl3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We take the FashionMNIST Dataset for our example"
      ],
      "metadata": {
        "id": "ed4W1BnPQXpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the data\n",
        "training_data = datasets.FashionMNIST(root=\"data\",train=True,download=True,transform=ToTensor(), target_transform=None)\n",
        "\n",
        "test_data = datasets.FashionMNIST(root=\"data\",train=False,download=True,transform=ToTensor(), target_transform=None)"
      ],
      "metadata": {
        "id": "Dld_zxhdRGvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Check the data shapes"
      ],
      "metadata": {
        "id": "6jHzLdda1Z9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimensions\n",
        "# print(f\"Input shape: {X.shape} | Output shape: {y.shape}\")"
      ],
      "metadata": {
        "id": "3N0GtUZc1eEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Visualize the data"
      ],
      "metadata": {
        "id": "N2EU5_Hl1P-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 Prepare the DataLoader\n",
        "\n",
        "The DataLoader turns our data into a python iterable and allows us to divide the data into mini batches. (https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
        "\n",
        "Why? - computational more efficient & mini batches (size k) give the network more chances to update the gradients per epoch."
      ],
      "metadata": {
        "id": "I_4PP-1i2ZzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch size hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# construct mini batches for the train and test data\n",
        "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# check the dimensions\n",
        "print(f\"Length of the train DataLoader: {len(train_dataloader)} batches of {BATCH_SIZE}. (Orignially {len(training_data)})\")\n",
        "print(f\"Length of the test DataLoader: {len(test_dataloader)} batches of {BATCH_SIZE}.  (Orignially {len(test_data)})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDc4T4yU3ymA",
        "outputId": "d3f94a05-8691-4963-f84b-ca16e34734a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the train DataLoader: 1875 batches of 32. (Orignially 60000)\n",
            "Length of the test DataLoader: 313 batches of 32.  (Orignially 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Build and train your model\n",
        "\n",
        "1. Build your own model or use an existing architecture\n",
        "1. Pick a loss function and optimizer\n",
        "3. Train the model"
      ],
      "metadata": {
        "id": "iMptlblwLXir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Build your own model or use an existing architecture\n",
        "\n",
        "1. Build the model\n",
        "2. Create a model instance"
      ],
      "metadata": {
        "id": "MVvMl5boNaiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model (start with a baseline model and increase the complexity or use an exisiting model architecture)\n",
        "class PytorchModel(nn.Module):\n",
        "  \"\"\"This is the Pytorch Model class. Since it inherits from nn.Module we have to override the forward() method\"\"\"\n",
        "\n",
        "  def __init__(self, input_shape:int,hidden_units:int,output_shape:int):\n",
        "    \"\"\"Constructor Initialization. Calls the super constructor and initializes our model.\"\"\"\n",
        "\n",
        "    # call the super constructor\n",
        "    super().__init__()\n",
        "\n",
        "    # create the model in several blocks\n",
        "\n",
        "    self.block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,out_channels=hidden_units, kernel_size=3,stride=1,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units, kernel_size=3,stride=1,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    )\n",
        "\n",
        "\n",
        "    self.block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units, kernel_size=3,stride=1,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units, kernel_size=3,stride=1,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    )\n",
        "\n",
        "    self.fully_connceted_layer = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=490, out_features=output_shape),\n",
        "    )\n",
        "\n",
        "  def forward(self,X):\n",
        "    \"\"\"\n",
        "    This function is mandatory in each pytorch model and calculates the foward pass.\n",
        "\n",
        "    :param X: tensor: The X data\n",
        "    :return y: tensor: The y data (prediction)\n",
        "    \"\"\"\n",
        "\n",
        "    # perform the calculations\n",
        "    X = self.block_1(X)\n",
        "    # print(f\"Dimension of model output: {X.shape}\")\n",
        "    X = self.block_2(X)\n",
        "    # print(f\"Dimension of model output: {X.shape}\")\n",
        "    X = self.fully_connceted_layer(X)\n",
        "    # print(f\"Dimension of model output: {X.shape}\")\n",
        "\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "YYGZW6Zs61Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model instance\n",
        "model = PytorchModel(input_shape=1,hidden_units=10,output_shape = 10)\n",
        "\n",
        "# send the model to the right device\n",
        "model = model.to(device)\n",
        "\n",
        "# print the model\n",
        "print(f\"{model}\")"
      ],
      "metadata": {
        "id": "wAqXT0pjNme1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a30b5e7-9ac1-47b2-f87d-108a82ac346b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PytorchModel(\n",
            "  (block_1): Sequential(\n",
            "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (block_2): Sequential(\n",
            "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fully_connceted_layer): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dummy tensor with the same dimensions as your data, add batch dimensiona nd send it to your device\n",
        "dummy_tensor = torch.randn(size=(1,28,28)).unsqueeze(0).to(device)\n",
        "\n",
        "# pass the data through your model\n",
        "X_dummy = model(dummy_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw26JRWfjLWR",
        "outputId": "05deccdc-0eb5-4cc6-e159-afe54260ba03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -57.7645, -150.5729, -114.3710, -110.9344, -146.6168,   -8.3703,\n",
            "          -76.7071, -246.3527,  -50.3308, -107.6575]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Pick a loss function & optimizer\n",
        "\n",
        "1. Available loss functions: https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "2. Available optimizer: https://pytorch.org/docs/stable/optim.html#algorithms\n",
        "\n"
      ],
      "metadata": {
        "id": "9qsgtoGQKioq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up a loss function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# learning rate\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "# setup an optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "Zt1WozOmKixD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Creating a training loop and train a model on batches of data.\n",
        "\n",
        "1. Loop through the epochs\n",
        "2. Loop through the training batches, perform training steps and calculate the train loss.\n",
        "3. Loop through testing batches, perform testing steps and calculate the test loss."
      ],
      "metadata": {
        "id": "xKxymOdKvgsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# timing\n",
        "train_time_start = timer()"
      ],
      "metadata": {
        "id": "CJx6d_CStItl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of epochs\n",
        "EPOCHS = 3\n",
        "\n",
        "# create a training and test loop\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "\n",
        "  # printing\n",
        "  print(f\"Epoch: {epoch}\\n-------\")\n",
        "\n",
        "  # train loss counter\n",
        "  batch_train_loss = 0\n",
        "\n",
        "  # model to train mode\n",
        "  model.train()\n",
        "\n",
        "  # training: loop thorugh the training batches\n",
        "  for batch, (X_train,y_train) in enumerate(train_dataloader):\n",
        "\n",
        "    # put data on device\n",
        "    X_train,y_train = X_train.to(device), y_train.to(device)\n",
        "\n",
        "    # calculate the forward pass\n",
        "    y_pred_train = model(X_train)\n",
        "\n",
        "    # calculate the training loss and add (accumulate) the loss to the counter\n",
        "    training_loss = loss_function(y_pred_train,y_train)\n",
        "    batch_train_loss += training_loss\n",
        "\n",
        "    # optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # calcuate the loss backwards (backpropagation)\n",
        "    training_loss.backward()\n",
        "\n",
        "    # optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # per batch printing every 1000\n",
        "    if batch % 1000 == 0:\n",
        "      print(f\"Looked at {batch * len(X_train)} / {len(train_dataloader.dataset)} samples.\")\n",
        "\n",
        "  # divide total train loss by length of train dataloader: Average training loss per batch\n",
        "  batch_train_loss /= len(train_dataloader)\n",
        "\n",
        "  # validation loss counter\n",
        "  batch_val_loss = 0\n",
        "\n",
        "  # model to validation mode\n",
        "  model.eval()\n",
        "\n",
        "  # inference mode diasables gradient tracking\n",
        "  with torch.inference_mode():\n",
        "\n",
        "    # validation: loop thorugh the validation batches\n",
        "    for batch, (X_val,y_val) in enumerate(test_dataloader):\n",
        "\n",
        "      # put data on device\n",
        "      X_val,y_val = X_val.to(device), y_val.to(device)\n",
        "\n",
        "      # calculate the forward pass\n",
        "      y_pred_val = model(X_val)\n",
        "\n",
        "      # calculate the validation loss and add (accumulate) the loss to the counter\n",
        "      val_loss = loss_function(y_pred_val,y_val)\n",
        "      batch_val_loss += val_loss\n",
        "\n",
        "    # divide total validation loss by length of val dataloader: Average validation loss per batch\n",
        "    batch_val_loss /= len(test_dataloader)\n",
        "\n",
        "  # print\n",
        "  print(f\"Train Loss: {batch_train_loss:.5f} | Validation Loss:{batch_val_loss:.5f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345,
          "referenced_widgets": [
            "e4836431cf1c4ca49685b64f67797356",
            "32c2d40d8f994d3d99ed51cd05456692",
            "a62df14790f14d4caa011b0adda07d96",
            "48d5bcf62db740ada2b3541f715485b5",
            "f68137df8dae40c098e82b291555c32e",
            "84af123733e74bff83a5bf66f0d4a84c",
            "b9d39ba6cfd640ad8cd77554ff35e8fd",
            "dbae073c244a4c0b999f6b80aa6c4c83",
            "22e7fb5d496348f1ac18d6238ecc63c3",
            "d92339152f9a4e3d8618ecf25a7e2935",
            "7fee22269bc248bf9672aecf975cffda"
          ]
        },
        "id": "d4nL1Pa8wRXw",
        "outputId": "93ce3786-68f0-494d-cd66-12ae7bb6b04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4836431cf1c4ca49685b64f67797356"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "-------\n",
            "Looked at 0 / 60000 samples.\n",
            "Looked at 32000 / 60000 samples.\n",
            "Train Loss: 0.45611 | Validation Loss:0.38335\n",
            "\n",
            "Epoch: 1\n",
            "-------\n",
            "Looked at 0 / 60000 samples.\n",
            "Looked at 32000 / 60000 samples.\n",
            "Train Loss: 0.37083 | Validation Loss:0.39210\n",
            "\n",
            "Epoch: 2\n",
            "-------\n",
            "Looked at 0 / 60000 samples.\n",
            "Looked at 32000 / 60000 samples.\n",
            "Train Loss: 0.35588 | Validation Loss:0.39481\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_helper_functions import print_train_time\n",
        "\n",
        "# calculate the training time\n",
        "train_time_end = timer()\n",
        "total_train_time = print_train_time(train_time_start, train_time_end, device=str(next(model.parameters()).device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb18uwGb02KZ",
        "outputId": "8cb3dc4d-3ec1-49bc-847b-2142f15977c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train time on cuda:0: 42.149 seconds\n"
          ]
        }
      ]
    }
  ]
}