{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Import the needed Libraries\n",
        "\n",
        "#### Documentation: https://pytorch.org/docs/stable/index.html\n",
        "#### Youtube Tutorial: https://www.youtube.com/watch?v=kCc8FmEb1nY"
      ],
      "metadata": {
        "id": "t9vTzMfgNp3c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmcKOZLoNghd",
        "outputId": "decdda46-2334-4751-f191-aed48facc293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# pytorch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# torchvision\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# torchinfo\n",
        "%pip install torchinfo\n",
        "%pip install torchmetrics\n",
        "from torchinfo import summary\n",
        "\n",
        "# standard data handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# image\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# system\n",
        "import pathlib\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# timing and printing\n",
        "from tqdm.auto import tqdm\n",
        "from timeit import default_timer as timer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the available pytorch and Cuda (GPU) Version"
      ],
      "metadata": {
        "id": "sj1wRxNNNz6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pytroch and cuda version\n",
        "print(torch.__version__)\n",
        "\n",
        "# trochvision and cuda version\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJna7OTaN3RX",
        "outputId": "f12853ca-635c-491a-d805-5cd1f5d5deeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "0.15.2+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the available device\n",
        "\n",
        "1. CPU (Default)\n",
        "2. Cuda (GPU acceleration is accessible)"
      ],
      "metadata": {
        "id": "Yu4LgiFuN6ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make device agnostic code (default is cpu)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Available device is: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYwYACZTN9j5",
        "outputId": "54d77094-29a2-4018-d64b-ee9f7b323859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available device is: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Helper files"
      ],
      "metadata": {
        "id": "LxCfteedOFO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filenames\n",
        "filenames = {\"pytorch_helper_functions.py\": \"https://raw.githubusercontent.com/sl2000stat/PytorchIntroduction/master/pytorch_helper_functions.py\",\n",
        "             \"training.py\": \"https://raw.githubusercontent.com/sl2000stat/PytorchIntroduction/master/training.py\",\n",
        "             \"make_predictions.py\":\"https://raw.githubusercontent.com/sl2000stat/PytorchIntroduction/master/make_predictions.py\",\n",
        "             \"validation.py\":\"https://raw.githubusercontent.com/sl2000stat/PytorchIntroduction/master/validation.py\",\n",
        "             \"visualizing_images.py\":\"https://raw.githubusercontent.com/sl2000stat/PytorchIntroduction/master/visualizing_images.py\",\n",
        "\n",
        "             # get the data as text file\n",
        "             \"input.txt\" : \"https://raw.githubusercontent.com/karpathy/ng-video-lecture/master/input.txt\"}\n",
        "\n",
        "for filename, file_path in filenames.items():\n",
        "\n",
        "  # download helper functions from repo\n",
        "  if Path(filename).is_file():\n",
        "    print(f\"{filename} already exists. Skipping download\")\n",
        "\n",
        "  else:\n",
        "\n",
        "    request = requests.get(file_path)\n",
        "    with open(filename, \"wb\") as f:\n",
        "      f.write(request.content)\n",
        "\n",
        "    print(f\"Downloaded {filename}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh0MZ11vOFT-",
        "outputId": "c7360fa6-c5aa-4b79-fc51-a5395404cbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pytorch_helper_functions.py already exists. Skipping download\n",
            "training.py already exists. Skipping download\n",
            "make_predictions.py already exists. Skipping download\n",
            "validation.py already exists. Skipping download\n",
            "visualizing_images.py already exists. Skipping download\n",
            "input.txt already exists. Skipping download\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set the global Seed"
      ],
      "metadata": {
        "id": "bURjZNniOKM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_helper_functions import set_global_seed\n",
        "\n",
        "# set the global seed\n",
        "set_global_seed(42)"
      ],
      "metadata": {
        "id": "ESxA0G-OOKP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Replicate Transformer Model with Initial Paper: \"Attention is all you need\""
      ],
      "metadata": {
        "id": "eiwObiFyOPQj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Get the Data"
      ],
      "metadata": {
        "id": "w_Oe8w3vOYbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open the text file\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "-4DJsSdkRcXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the vocal size (set creates unique entries)\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "id": "6088gm6-Re3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Encode the Text Data"
      ],
      "metadata": {
        "id": "4agPAJAvRNFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "# encoder: take a string, output a list of integers\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "\n",
        "# decoder: take a list of integers, output a string\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "# print some examples\n",
        "print(encode(\"Hello There\"))\n",
        "print(decode(encode(\"Hello There\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEwrIy7lPKLD",
        "outputId": "dbcc070c-f2fc-4a8b-923c-979b79ed478f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20, 43, 50, 50, 53, 1, 32, 46, 43, 56, 43]\n",
            "Hello There\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Split the Text Data into Training and Validatiaon sets"
      ],
      "metadata": {
        "id": "BfRu16smTfLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert data to tensors\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "\n",
        "# training and test splits\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# shapes printing\n",
        "print(f\"Shape of Train Data: {train_data.shape} | Shape of Val Data: {val_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK3_N_4wRZ2G",
        "outputId": "e4861b7b-c0ca-4a0f-be73-732a6c9a16eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Train Data: torch.Size([1003854]) | Shape of Val Data: torch.Size([111540])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Batching The Data"
      ],
      "metadata": {
        "id": "6jjZ_gHSTm8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(data,BATCH_SIZE:int,BLOCK_SIZE:int):\n",
        "    \"\"\"\"\"\"\n",
        "\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    ix = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE,))\n",
        "    x = torch.stack([data[i:i+BLOCK_SIZE] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+BLOCK_SIZE+1] for i in ix])\n",
        "\n",
        "    # send the data to the device\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "6pBa2fvuTpWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how many independent sequences will we process in parallel?\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# what is the maximum context length for predictions?\n",
        "BLOCK_SIZE = 256"
      ],
      "metadata": {
        "id": "7SJKUuiGT2HM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}