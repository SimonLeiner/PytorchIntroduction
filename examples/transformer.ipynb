{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9vTzMfgNp3c"
      },
      "source": [
        "# Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmcKOZLoNghd",
        "outputId": "decdda46-2334-4751-f191-aed48facc293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# pytorch\n",
        "import torch\n",
        "\n",
        "# torchvision\n",
        "import torchvision\n",
        "\n",
        "\n",
        "# torchinfo\n",
        "%pip install torchinfo\n",
        "%pip install torchmetrics\n",
        "\n",
        "# standard data handling\n",
        "\n",
        "# plotting\n",
        "\n",
        "# image\n",
        "\n",
        "# system\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "\n",
        "# timing and printing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj1wRxNNNz6g"
      },
      "source": [
        "### Check the available pytorch and Cuda (GPU) Version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJna7OTaN3RX",
        "outputId": "f12853ca-635c-491a-d805-5cd1f5d5deeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.1+cu118\n",
            "0.15.2+cu118\n"
          ]
        }
      ],
      "source": [
        "# pytroch and cuda version\n",
        "print(torch.__version__)\n",
        "\n",
        "# trochvision and cuda version\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu4LgiFuN6ju"
      },
      "source": [
        "### Check the available device\n",
        "\n",
        "1. CPU (Default)\n",
        "2. Cuda (GPU acceleration is accessible)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYwYACZTN9j5",
        "outputId": "54d77094-29a2-4018-d64b-ee9f7b323859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available device is: cpu\n"
          ]
        }
      ],
      "source": [
        "# make device agnostic code (default is cpu)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Available device is: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxCfteedOFO9"
      },
      "source": [
        "### Import Helper files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh0MZ11vOFT-",
        "outputId": "c7360fa6-c5aa-4b79-fc51-a5395404cbbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pytorch_helper_functions.py already exists. Skipping download\n",
            "training.py already exists. Skipping download\n",
            "make_predictions.py already exists. Skipping download\n",
            "validation.py already exists. Skipping download\n",
            "visualizing_images.py already exists. Skipping download\n",
            "input.txt already exists. Skipping download\n"
          ]
        }
      ],
      "source": [
        "# filenames\n",
        "filenames = {\n",
        "    \"pytorch_helper_functions.py\": \"https://raw.githubusercontent.com/sl2000stat/PytorchIntroduction/master/pytorch_helper_functions.py\",\n",
        "    \"training.py\": \"https://raw.githubusercontent.com/sl2000stat/PytorchIntroduction/master/training.py\",\n",
        "    \"make_predictions.py\": \"https://raw.githubusercontent.com/sl2000stat/PytorchIntroduction/master/make_predictions.py\",\n",
        "    \"validation.py\": \"https://raw.githubusercontent.com/sl2000stat/PytorchIntroduction/master/validation.py\",\n",
        "    \"visualizing_images.py\": \"https://raw.githubusercontent.com/sl2000stat/PytorchIntroduction/master/visualizing_images.py\",\n",
        "    # get the data as text file\n",
        "    \"input.txt\": \"https://raw.githubusercontent.com/karpathy/ng-video-lecture/master/input.txt\",\n",
        "}\n",
        "\n",
        "for filename, file_path in filenames.items():\n",
        "    # download helper functions from repo\n",
        "    if Path(filename).is_file():\n",
        "        print(f\"{filename} already exists. Skipping download\")\n",
        "\n",
        "    else:\n",
        "        request = requests.get(file_path)\n",
        "        with open(filename, \"wb\") as f:\n",
        "            f.write(request.content)\n",
        "\n",
        "        print(f\"Downloaded {filename}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bURjZNniOKM2"
      },
      "source": [
        "### Set the global Seed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESxA0G-OOKP0"
      },
      "outputs": [],
      "source": [
        "from pytorch_helper_functions import set_global_seed\n",
        "\n",
        "\n",
        "# set the global seed\n",
        "set_global_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiwObiFyOPQj"
      },
      "source": [
        "### Replicate Transformer Model with Initial Paper: \"Attention is all you need\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_Oe8w3vOYbZ"
      },
      "source": [
        "### 1. Get the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4DJsSdkRcXH"
      },
      "outputs": [],
      "source": [
        "# open the text file\n",
        "with open(\"input.txt\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6088gm6-Re3-"
      },
      "outputs": [],
      "source": [
        "# get the vocal size (set creates unique entries)\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4agPAJAvRNFf"
      },
      "source": [
        "### 1.2 Encode the Text Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEwrIy7lPKLD",
        "outputId": "dbcc070c-f2fc-4a8b-923c-979b79ed478f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[20, 43, 50, 50, 53, 1, 32, 46, 43, 56, 43]\n",
            "Hello There\n"
          ]
        }
      ],
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# encoder: take a string, output a list of integers\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "\n",
        "# decoder: take a list of integers, output a string\n",
        "decode = lambda l: \"\".join([itos[i] for i in l])\n",
        "\n",
        "# print some examples\n",
        "print(encode(\"Hello There\"))\n",
        "print(decode(encode(\"Hello There\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfRu16smTfLu"
      },
      "source": [
        "### 1.3 Split the Text Data into Training and Validatiaon sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK3_N_4wRZ2G",
        "outputId": "e4861b7b-c0ca-4a0f-be73-732a6c9a16eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of Train Data: torch.Size([1003854]) | Shape of Val Data: torch.Size([111540])\n"
          ]
        }
      ],
      "source": [
        "# convert data to tensors\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "\n",
        "# training and test splits\n",
        "n = int(0.9 * len(data))  # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# shapes printing\n",
        "print(f\"Shape of Train Data: {train_data.shape} | Shape of Val Data: {val_data.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jjZ_gHSTm8q"
      },
      "source": [
        "### 1.4 Batching The Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pBa2fvuTpWE"
      },
      "outputs": [],
      "source": [
        "def get_batch(data, BATCH_SIZE: int, BLOCK_SIZE: int):\n",
        "    \"\"\"\"\"\"\n",
        "\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    ix = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE,))\n",
        "    x = torch.stack([data[i : i + BLOCK_SIZE] for i in ix])\n",
        "    y = torch.stack([data[i + 1 : i + BLOCK_SIZE + 1] for i in ix])\n",
        "\n",
        "    # send the data to the device\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SJKUuiGT2HM"
      },
      "outputs": [],
      "source": [
        "# how many independent sequences will we process in parallel?\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# what is the maximum context length for predictions?\n",
        "BLOCK_SIZE = 256"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
